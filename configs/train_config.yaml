# --- General Training Configuration ---
experiment_name: "dualfocus_pretrain_exp" # Unique name for this experiment run
output_dir: "./training_output"        # Base directory for logs and checkpoints
seed: 2       #42                       # Random seed for reproducibility
resume_from_checkpoint: true         # Set to true to attempt resuming from the latest checkpoint

# --- Dataset Configuration ---
dataset:
  name: "VideoInstruction"
  train_json_path: "/data/datasets/video_qa.json" # Path to training JSON
  val_json_path: "/data/datasets/video_val_qa.json"    # Path to validation JSON
  video_dir: "/data/datasets/videos"         # Path to video files (e.g., videoXXXX.mp4)
  num_frames_r: -2
  num_frames_m: -2

# --- Dataloader Configuration ---
dataloader:
  batch_size_per_device: 1            # Batch size per GPU
  num_workers: 2                      # Number of workers for data loading

# --- Model Configuration (matches DualFocusVideoQA __init__) ---
model:
  qvit_model_config:
    qa_instruction_point: 'late'
    instruction_dim: 4096             # Should match LLM hidden dim (auto-set in DualFocus if llm loaded first)
    hidden_dim: 1408                  # QA-ViT output dim
    eva_img_size: 224
    drop_path_rate: 0.0
    image_processor_id: "../models/vit_image_processor" # Processor for QA-ViT
    cached_file: "../models/eva_vit_g.pth"             # QA-ViT weights
  vit_model_id: "../models/eva"      # Path or ID for the second vision model (e.g., Siglip or Dino)
  llm_model_id: "../models/vicuna"      # Path or ID for the LLM
  qformer_model_id: "../models/instruct_blip_vicuna7b_trimmed.pth" # Q-Former checkpoint or base model ID ('bert-base-uncased')
  qformer_num_query: 32
  qformer_max_txt_len: 128
  dinov2_output_layer: -2             # Relevant if using DinoV2
  max_frames: 500                      # Max frames expected by internal buffers (e.g., pos encoding)
  feature_map_intermediate_dim: null  # Optional intermediate dim for projector, null for default
  freeze_llm: true
  freeze_vit: true                    # Freeze the second vision model base
  freeze_qvit_base: true              # Freeze QA-ViT base
  freeze_qformer_base: true           # Freeze Q-Former BERT base

# --- Training Procedure ---
training:
  num_epochs: 3
  save_steps: 500                   # Save checkpoint every N training steps (processed items)
  eval_steps: 500                   # Evaluate on validation set every N steps
  # Optimizer/Scheduler params are usually in deepspeed config, but can be here for reference
  # learning_rate: 1e-5
  # weight_decay: 0.01

# --- DeepSpeed Configuration ---
deepspeed_config_path: "train_ds_config.json"